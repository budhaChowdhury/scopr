#' @importFrom data.table ":="
NULL

#' Read data from an ethoscope result file
#'
#' This function is used to convert all the information
#' contained in a result file generated by the [ethoscope platform](http://gilestrolab.github.io/ethoscope/)
#' (i.e a .db file) into an `R` `data.table`.
#'
#' @param result_dir the root directory where all daily data are saved
#' @param query [data.frame] representing a formatted query used to request data (see detail)
#' @param min_time Exclude data before min_time (in seconds).
#' This time is *relative to the start of the experiment*.
#' @param max_time Exclude data after max_time (in seconds).
#' It is also relative to the start of the experiment.
#' @param reference_hour Hour, in the day, to use as ZT0 reference.
#' When unspecified, time will be relative to the start of the experiment.
#' @param verbose whether to print progress (a logical).
#' @param columns Optionnal vector of columns to be selected from the db file.
#' Time (t) is always implicitely selected.
#' @param ncores Number of cores to use for optionnal parallel processing.
#' @param FUN function (optional) to transform the data from each animal
#' immediately after is has been loaded.
#' @param ... extra arguments to be passed to `FUN`
#' @return A [behavr] table.
#' The metadata contains all the query columns and an autogenerated id per animal.
#' The data has the columns:
#' * `id` -- autogenerated unique identifier, one per animal
#' * `t` -- time
#' * Several variables recorded by ethoscopes (position, angle, width/height and others).
#' Distance units (e.g. xy position, height/width) are expressed as a fraction of the width of the ROI they originate from.
#' @details
#' todo
#' @examples
#' \donttest{
#' todo
#' }
#' @seealso TODO
#' @export
query_ethoscopes <- function(result_dir,
                              query=NULL,
                              min_time = 0,
                              max_time = Inf,
                              reference_hour=NULL,
                              verbose=TRUE,
                              columns = NULL,
                              ncores=1,
                              FUN=NULL,
                              ...){
  # from the `what` argument, we build a `master_table` that we will map to the actual data.
  master_table <- makeMasterTable(query)

  # Each row of master table refers to a unique ROI. to each ROI we apply the function `parseOneROI`
  # and get each ROI in a dt.
  # So, l_dt is a list of data tables, one per ROI. If no data is availeble, the list element is `NULL`.

  if(ncores == 1){
    l_dt <- lapply(1:nrow(master_table),parseOneROI, master_table,min_time, max_time, reference_hour,verbose,columns=columns,FUN,...)
  }
  else{
    if (!requireNamespace("parallel", quietly = TRUE)) {
      stop("`parallel` package needed for ncores > 1.
           Please install it.",
           call. = FALSE)
    }
    # cl <- makeCluster(getOption("cl.cores", ncores))
    # clusterExport(cl, "master_table")
    l_dt <- parallel::mclapply(1:nrow(master_table),parseOneROI,
                               mc.cores=ncores,
                               master_table,min_time, max_time,
                               reference_hour, verbose,columns=columns,FUN,...)
  }

  # if any element of the list is `NULL`, then it is removed
  l_dt <- l_dt[!sapply(l_dt,is.null)]

  #all data table in the list should have the same key
  if(length(unique(lapply(l_dt,key))) > 1){
    stop("Data tables do not have the same keys")
  }
  # if they have the same keys, then  the key for everyone is:
  keys <- key(l_dt[[1]])

  # then we bin ALL roi tables in one datatable with all ROIs in
  out <- rbindlist(l_dt)

  # now we remove l_dt as it is expected to be quite large
  rm(l_dt)
  # we also can force R to garbage collect, making memory avalable:
  gc()

  # we reasign the correct key to the output data table
  setkeyv(out, keys)

  # we join master and out, so extra, user defined, cols are no in out
  out <- master_table[out]

  # we don't want path in out, it is too long and inconsistent
  out[, path := NULL]

  master_table[, path := NULL]

  # we want all user defined variables AND the default key (region_id, experiment_id) to be key.
  setkeyv(out, colnames(master_table))
  out
  }
