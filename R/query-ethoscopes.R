#' @importFrom data.table ":="
#' @importFrom data.table "key"
#' @import behavr
NULL

#' Read data from ethoscope result files
#'
#' This function is used to import behavioural data generated
#' by the [ethoscope platform](http://gilestrolab.github.io/ethoscope/).
#' That is it loads multiple `.db`` files into a single `R` [behavr::behavr] table.
#'
#' @param query [data.table::data.table] obtained by [parse_query]
#' @param min_time Exclude data before min_time (in seconds).
#' This time is *relative to the start of the experiment*.
#' @param max_time Exclude data after max_time (in seconds).
#' It is also relative to the start of the experiment.
#' @param reference_hour Hour, in the day, to use as ZT0 reference.
#' When unspecified, time will be relative to the start of the experiment.
#' @param verbose whether to print progress (a logical)
#' @param columns optionnal vector of columns to be selected from the db file.
#' Time (t) is always implicitely selected.
#' @param cache the name of a local directory to cache results for faster subsequent data loading
#' @param ncores number of cores to use for optionnal parallel processing
#' @param FUN function (optional) to transform the data from each individual
#' immediately after is has been loaded.
#' @param ... extra arguments to be passed to `FUN`
#' @return a [behavr] table.
#' The metadata contains all the query columns and an autogenerated id per animal.
#' The data has the columns:
#' * `id` -- autogenerated unique identifier, one per animal
#' * `t` -- time
#' * Several variables recorded by ethoscopes (position, angle, width/height and others).
#' Distance units (e.g. xy position, height/width) are expressed as a fraction of the width of the ROI they originate from.
#' @details
#' todo
#' @examples
#' dir <- paste0(scopr_example_dir(), "/ethoscope_results/")
#' data(region_id_query)
#' query <- parse_query(region_id_query, dir)
#' print(query)
#'
#' # default data loading
#' dt <- query_ethoscopes(query)
#' dt
#'
#' # we use reference hour to set zt0 to 09:00 GMT
#' dt <- query_ethoscopes(query, reference_hour=9)
#' dt
#'
#' #' # only load x and y positions
#' dt <- query_ethoscopes(query, columns=c("x", "y"), reference_hour=9)
#' dt
#' # apply function whilst loading the data
#' # todo use sleepr
#' dt <- query_ethoscopes(query, reference_hour=9, FUN=head)
#' dt
#'
#' @seealso
#' * [behavr::behavr] -- to understand the output format
#' * [parse_query] -- to generate a query
#' * [read_metadata] -- to show the metadata of a specific experiment
#' * [list_result_files] -- to list available files
#' @references
#' * todo
#' @export
query_ethoscopes <- function( query,
                              min_time = 0,
                              max_time = Inf,
                              reference_hour = NULL,
                              verbose = TRUE,
                              columns = NULL,
                              cache = NULL,
                              ncores = 1,
                              FUN = NULL,
                              ...){


  # takes a part of a query and et the corresponding data
  load_fun <- function(q){
    # Each row of query refers to a unique ROI. to each ROI we apply the function `parse_single_roi`
    # and get each ROI in a dt.
    # So, l_dt is a list of data tables, one per ROI. If no data is availeble, the list element is `NULL`.

    l_rows <- lapply(1:nrow(q),function(i){q[i,]})
    l_dt <- lapply(l_rows,parse_single_roi,
                   min_time = min_time,
                   max_time = max_time,
                   reference_hour = reference_hour,
                   verbose = verbose,
                   columns=columns,
                   cache=cache,
                   FUN,...)
    dt <- behavr::bind_behavr_list(l_dt)
    dt
  }

  q_l <- split(query, by="experiment_id")

  if(ncores == 1){
    l_dt <- lapply(q_l, load_fun)
  }
  else{
    if (!requireNamespace("parallel", quietly = TRUE)) {
      stop("`parallel` package needed for ncores > 1.
           Please install it.",
           call. = FALSE)
    }
    l_dt <- parallel::mclapply(q_l, load_fun, mc.cores=ncores)
  }

  dt <- behavr::bind_behavr_list(l_dt)
  rm(l_dt)
  # we can force R to garbage collect, making memory avalable:
  gc()
  dt
}


